"""
REALCARTOON XL V7 WITH COMPEL LONG PROMPTS - NO MASKING VERSION
Demonstrates character blending issues without masking for research paper!

âœ… KEY FEATURES:
- Uses Compel library to handle prompts longer than 77 tokens
- NO masking or ControlNet - shows raw character blending issues
- Detailed prompts for better SDXL results
- Simple IP-Adapter integration without spatial control
- Perfect for demonstrating WHY masking is necessary!
"""

import os
import torch
import time
from PIL import Image
from diffusers import StableDiffusionXLPipeline, DDIMScheduler
from transformers import CLIPVisionModelWithProjection
from compel import Compel, ReturnedEmbeddingsType
import traceback
import gc

class CompelNoMaskingPipeline:
    """Pipeline with Compel support for long prompts - NO MASKING to show character blending"""
    
    def __init__(self, model_path, device="cuda"):
        self.model_path = model_path
        self.device = device
        self.pipeline = None
        self.compel = None
        self.ip_adapter_loaded = False
        
    def setup_pipeline_with_compel(self):
        """Setup pipeline with Compel for long prompt support - NO ControlNet or masking"""
        print("ğŸ”§ Setting up RealCartoon XL v7 with Compel (NO MASKING - Character Blending Demo)...")
        
        try:
            # Verify model
            size_gb = os.path.getsize(self.model_path) / (1024**3)
            print(f"   ğŸ“Š Model: {size_gb:.1f}GB")
            if 6.5 <= size_gb <= 7.5:
                print("   âœ… RealCartoon XL v7 confirmed")
            
            # Load image encoder first
            print("   ğŸ“¸ Loading image encoder...")
            image_encoder = CLIPVisionModelWithProjection.from_pretrained(
                "h94/IP-Adapter",
                subfolder="models/image_encoder",
                torch_dtype=torch.float16,
            )
            
            # Load ONLY regular pipeline - no ControlNet
            print("   ğŸ¯ Loading RealCartoon XL v7 (regular pipeline only)...")
            self.pipeline = StableDiffusionXLPipeline.from_single_file(
                self.model_path,
                torch_dtype=torch.float16,
                use_safetensors=True,
                image_encoder=image_encoder,
                safety_checker=None,
                requires_safety_checker=False
            ).to(self.device)
            
            # Setup scheduler
            print("   ğŸ“ Setting up scheduler...")
            self.pipeline.scheduler = DDIMScheduler.from_config(self.pipeline.scheduler.config)
            self.pipeline.enable_vae_tiling()
            
            # Setup Compel for long prompts (CRITICAL!)
            print("   ğŸš€ Setting up Compel for long prompts...")
            self.compel = Compel(
                tokenizer=[self.pipeline.tokenizer, self.pipeline.tokenizer_2],
                text_encoder=[self.pipeline.text_encoder, self.pipeline.text_encoder_2],
                returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,
                requires_pooled=[False, True],
                truncate_long_prompts=False  # This enables long prompts!
            )
            
            print("âœ… Pipeline with Compel ready!")
            print("   ğŸ¯ Long prompts (>77 tokens) now supported!")
            print("   âš ï¸ NO MASKING - will demonstrate character blending issues!")
            return True
            
        except Exception as e:
            print(f"âŒ Pipeline setup failed: {e}")
            traceback.print_exc()
            return False
    
    def load_ip_adapter_simple(self):
        """Load IP-Adapter with simple configuration"""
        print("\nğŸ–¼ï¸ Loading IP-Adapter (NO masking support)...")
        
        try:
            # Load IP-Adapter for regular pipeline
            self.pipeline.load_ip_adapter(
                "h94/IP-Adapter",
                subfolder="sdxl_models",
                weight_name=["ip-adapter-plus-face_sdxl_vit-h.safetensors"]
            )
            self.ip_adapter_loaded = True
            print("   âœ… IP-Adapter loaded!")
            print("   âš ï¸ NO masking capability - characters will blend!")
            
            return True
            
        except Exception as e:
            print(f"   âŒ IP-Adapter failed: {e}")
            return False
    
    def encode_prompts_with_compel(self, positive_prompt, negative_prompt):
        """Encode both prompts using Compel and ensure matching shapes"""
        try:
            print(f"   ğŸ“ Encoding positive prompt: {positive_prompt[:100]}{'...' if len(positive_prompt) > 100 else ''}")
            print(f"   ğŸ“Š Positive prompt length: {len(positive_prompt.split())} words")
            
            print(f"   ğŸ“ Encoding negative prompt: {negative_prompt[:100]}{'...' if len(negative_prompt) > 100 else ''}")
            print(f"   ğŸ“Š Negative prompt length: {len(negative_prompt.split())} words")
            
            # Use Compel to handle both prompts
            positive_conditioning, positive_pooled = self.compel(positive_prompt)
            negative_conditioning, negative_pooled = self.compel(negative_prompt)
            
            # CRITICAL: Pad conditioning tensors to same length to avoid shape mismatch
            print("   ğŸ”§ Padding tensors to same length...")
            [positive_conditioning, negative_conditioning] = self.compel.pad_conditioning_tensors_to_same_length(
                [positive_conditioning, negative_conditioning]
            )
            
            print(f"   âœ… Final tensor shapes: pos={positive_conditioning.shape}, neg={negative_conditioning.shape}")
            
            return positive_conditioning, positive_pooled, negative_conditioning, negative_pooled
            
        except Exception as e:
            print(f"   âŒ Compel encoding failed: {e}")
            traceback.print_exc()
            return None, None, None, None
    
    def generate_reference_with_compel(self, prompt, negative_prompt, **kwargs):
        """Generate character reference using Compel for long prompts"""
        try:
            # Encode both prompts with Compel and ensure matching shapes
            prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled = self.encode_prompts_with_compel(
                prompt, negative_prompt
            )
            
            if prompt_embeds is None:
                return None
            
            result = self.pipeline(
                prompt_embeds=prompt_embeds,
                pooled_prompt_embeds=pooled_prompt_embeds,
                negative_prompt_embeds=negative_embeds,
                negative_pooled_prompt_embeds=negative_pooled,
                **kwargs
            )
            
            # Clean up embeddings to save memory
            del prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled
            gc.collect()
            
            return result.images[0] if result and result.images else None
            
        except Exception as e:
            print(f"âŒ Reference generation failed: {e}")
            traceback.print_exc()
            return None
    
    def generate_single_character_scene_with_compel(self, prompt, negative_prompt, character_ref, **kwargs):
        """Generate single character scene using Compel"""
        
        if not self.ip_adapter_loaded:
            print("   âŒ IP-Adapter not loaded!")
            return None
        
        try:
            # Encode both prompts with Compel and ensure matching shapes
            prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled = self.encode_prompts_with_compel(
                prompt, negative_prompt
            )
            
            if prompt_embeds is None:
                return None
            
            # Simple IP-Adapter configuration
            self.pipeline.set_ip_adapter_scale(0.7)
            
            result = self.pipeline(
                prompt_embeds=prompt_embeds,
                pooled_prompt_embeds=pooled_prompt_embeds,
                negative_prompt_embeds=negative_embeds,
                negative_pooled_prompt_embeds=negative_pooled,
                ip_adapter_image=character_ref,
                **kwargs
            )
            
            # Clean up embeddings
            del prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled
            gc.collect()
            
            return result.images[0] if result and result.images else None
            
        except Exception as e:
            print(f"âŒ Single character generation failed: {e}")
            traceback.print_exc()
            return None
    
    def generate_dual_character_scene_NO_MASKING(self, prompt, negative_prompt, alex_ref, emma_ref, **kwargs):
        """Generate dual character scene WITHOUT masking - demonstrates blending issues!"""
        
        if not self.ip_adapter_loaded:
            print("   âŒ IP-Adapter not loaded!")
            return None
        
        try:
            print("   âš ï¸ Generating dual characters WITHOUT masking - expect blending issues!")
            
            # Encode prompts with Compel
            prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled = self.encode_prompts_with_compel(
                prompt, negative_prompt
            )
            
            if prompt_embeds is None:
                return None
            
            # NO MASKING - just pass both character references directly
            # This will cause characters to blend/merge together!
            self.pipeline.set_ip_adapter_scale(0.7)
            
            # Try different approaches to show various blending issues:
            blending_method = kwargs.pop('blending_method', 'both_refs')
            
            if blending_method == 'both_refs':
                # Method 1: Pass both references - they will compete and blend
                print("   ğŸ“ Method: Both references (will compete and blend)")
                ip_adapter_image = [alex_ref, emma_ref]
                
            elif blending_method == 'single_dominant':
                # Method 2: Use one reference - other character gets lost
                print("   ğŸ“ Method: Single reference (one character dominates)")
                ip_adapter_image = alex_ref  # Emma will likely be lost or distorted
                
            elif blending_method == 'averaged':
                # Method 3: Try to blend references - creates hybrid features
                print("   ğŸ“ Method: Reference blending (creates hybrid features)")
                ip_adapter_image = [alex_ref, emma_ref]
                self.pipeline.set_ip_adapter_scale([0.5, 0.5])  # Equal weights
            
            # Generate WITHOUT any spatial control or masking
            result = self.pipeline(
                prompt_embeds=prompt_embeds,
                pooled_prompt_embeds=pooled_prompt_embeds,
                negative_prompt_embeds=negative_embeds,
                negative_pooled_prompt_embeds=negative_pooled,
                ip_adapter_image=ip_adapter_image,
                **kwargs
            )
            
            print("   âš ï¸ Generated without masking - check for character blending!")
            
            # Clean up embeddings
            del prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled
            gc.collect()
            
            return result.images[0] if result and result.images else None
            
        except Exception as e:
            print(f"âŒ Dual character generation failed: {e}")
            traceback.print_exc()
            return None

class DetailedEducationalPrompts:
    """Detailed prompts optimized for SDXL with Compel (no 77-token limit!)"""
    
    def __init__(self):
        # Detailed character descriptions for SDXL
        self.alex_base = """Alex, a cheerful 6-year-old boy with short neat black hair and warm expressive brown eyes, 
        wearing a comfortable bright blue t-shirt and dark comfortable pants, displaying a genuine friendly smile 
        and kind facial expression, with a natural child-like innocent demeanor"""
        
        self.emma_base = """Emma, a sweet 6-year-old girl with blonde hair styled in neat ponytails held by blue ribbons, 
        bright blue eyes full of curiosity, wearing a soft pink cardigan over a white shirt, 
        with a gentle sweet expression and delicate youthful features, displaying a thoughtful and sensitive nature"""
        
        self.setting_base = """bright cheerful classroom environment with warm natural lighting, 
        educational cartoon art style with soft colors and clean lines, child-friendly atmosphere, 
        professional educational illustration quality"""
        
    def get_reference_prompt(self, character_name):
        """Detailed reference prompts (no token limit with Compel!)"""
        if character_name == "Alex":
            return f"""{self.alex_base}, character reference sheet, full body portrait, 
            standing pose, clean white background, high quality digital illustration, 
            consistent character design, educational animation style, bright even lighting, 
            clear details, professional character concept art"""
        else:
            return f"""{self.emma_base}, character reference sheet, full body portrait, 
            standing pose, clean white background, high quality digital illustration, 
            consistent character design, educational animation style, bright even lighting, 
            clear details, professional character concept art"""
    
    def get_scene_prompt(self, skill, character_focus, action):
        """Detailed scene prompts (no token limit with Compel!)"""
        if character_focus == "Alex":
            return f"""{self.alex_base}, {action}, {self.setting_base}, 
            autism education themed illustration, social skills learning context, 
            high quality educational content, detailed facial expressions showing emotion, 
            natural body language and gestures, warm inviting atmosphere, 
            child-appropriate content, positive educational messaging"""
        elif character_focus == "Emma":
            return f"""{self.emma_base}, {action}, {self.setting_base}, 
            autism education themed illustration, social skills learning context, 
            high quality educational content, detailed facial expressions showing emotion, 
            natural body language and gestures, warm inviting atmosphere, 
            child-appropriate content, positive educational messaging"""
        else:  # both characters - this will show blending issues!
            return f"""Alex and Emma, two distinct children with clearly different appearances, Alex with black hair and blue shirt, Emma with blonde ponytails and pink cardigan, {action}, {self.setting_base}, 
            social skills education illustration, autism awareness content, showing positive social interaction, 
            detailed character expressions and body language, warm educational atmosphere, 
            high quality digital illustration, child-friendly educational content, 
            demonstrating friendship and social learning, bright cheerful colors, 
            two separate children clearly visible, distinct character features"""
    
    def get_negative_prompt(self):
        """Enhanced negative prompt to try to prevent blending (though it won't work without masking)"""
        return """realistic photography, photorealistic, adult faces, teenage appearance, 
        blurry image, low quality, poor resolution, dark lighting, scary atmosphere, 
        inappropriate content, weapons, violence, sad or distressing themes, 
        poor anatomy, distorted faces, multiple heads, extra limbs, 
        bad hands, mutation, deformed features, background characters, other people,
        merged faces, blended features, hybrid characters, face morphing, character fusion"""

def find_realcartoon_model():
    """Find RealCartoon XL v7 model"""
    paths = [
        "../models/realcartoonxl_v7.safetensors",
        "models/realcartoonxl_v7.safetensors",
        "../models/RealCartoon-XL-v7.safetensors"
    ]
    
    for path in paths:
        if os.path.exists(path):
            return path
    return None

def main():
    """RealCartoon XL v7 with Compel Long Prompts - NO MASKING (Character Blending Demo)"""
    print("\n" + "="*70)
    print("ğŸš€ REALCARTOON XL V7 - NO MASKING VERSION (CHARACTER BLENDING DEMO)")
    print("   Demonstrates WHY masking is necessary for dual character scenes!")
    print("="*70)
    
    print("\nğŸ¯ Demo Features:")
    print("  â€¢ Uses Compel for long prompts (>77 tokens)")
    print("  â€¢ NO masking or spatial control")
    print("  â€¢ NO ControlNet")
    print("  â€¢ Shows character blending/merging issues")
    print("  â€¢ Perfect for research paper comparison!")
    print("  â€¢ Demonstrates the PROBLEM that masking solves")
    
    print("\nâš ï¸ EXPECTED ISSUES WITHOUT MASKING:")
    print("  â€¢ Characters will blend together")
    print("  â€¢ One character may dominate")
    print("  â€¢ Hybrid facial features")
    print("  â€¢ Inconsistent character appearance")
    print("  â€¢ Poor spatial separation")
    
    # Check if Compel is installed
    try:
        import compel
        print("  âœ… Compel library detected")
    except ImportError:
        print("  âŒ Compel library not found!")
        print("     Install with: pip install compel")
        return
    
    # Find model
    model_path = find_realcartoon_model()
    if not model_path:
        model_path = input("ğŸ“ Enter RealCartoon XL v7 path: ").strip()
        if not os.path.exists(model_path):
            print("âŒ Model not found")
            return
    
    output_dir = "no_masking_blending_demo"
    os.makedirs(output_dir, exist_ok=True)
    
    # Setup pipeline with Compel (NO masking/ControlNet)
    pipeline = CompelNoMaskingPipeline(model_path)
    if not pipeline.setup_pipeline_with_compel():
        print("âŒ Pipeline setup failed")
        return
    
    prompts = DetailedEducationalPrompts()
    
    # Define comprehensive story scenes to show blending issues
    blending_demo_scenes = [
        # Single character scenes for reference
        ("01_alex_noticing", "single", "Alex", 
         "Alex alone, looking around the classroom with a concerned and empathetic expression on his face, with gentle body language showing he wants to help someone, kind and thoughtful demeanor"),
        
        ("02_emma_lonely", "single", "Emma", 
         "Emma alone, sitting at a desk with a book, looking sad and wistful, hoping for friendship and social connection, with expressive eyes showing her desire to interact with others"),
        
        ("03_alex_thinking", "single", "Alex", 
         "Alex alone at his desk with a thinking expression, pondering how to approach and help Emma"),
        
        # Dual character scenes WITHOUT masking - will show blending issues
        ("04_approaching", "dual", "both", 
         "Alex walking towards Emma at her desk while Emma looks up with cautious but hopeful expression, showing the beginning of positive social interaction",
         "both_refs"),
        
        ("05_greeting", "dual", "both", 
         "Alex and Emma doing a high five together, hands raised up and touching, both smiling happily, celebrating their new friendship",
         "both_refs"),
        
        ("06_playing_together", "dual", "both", 
         "Alex and Emma playing with educational toys together, showing cooperation and shared enjoyment, with happy expressions and collaborative interaction",
         "both_refs"),
        
        ("07_sharing", "dual", "both", 
         "Alex and Emma sharing books and educational materials, demonstrating generosity and friendship, with caring expressions and positive social behavior",
         "both_refs"),
        
        ("08_conversation", "dual", "both", 
         "Alex and Emma having a friendly conversation, sitting at a table facing each other, both engaged and listening to each other",
         "single_dominant"),
        
        ("09_learning_together", "dual", "both", 
         "Alex and Emma working on a puzzle together, heads close together as they collaborate, showing teamwork and friendship",
         "high_conflict"),
        
        ("10_comfort", "dual", "both", 
         "Alex gently comforting Emma, placing a reassuring hand on her shoulder, showing empathy and kindness",
         "high_conflict"),
        
        ("11_celebration", "dual", "both", 
         "Alex and Emma jumping with joy and excitement, arms raised in celebration, both children clearly visible and happy",
         "high_conflict"),
        
        ("12_reading_together", "dual", "both", 
         "Alex and Emma sitting side by side reading the same book, heads tilted toward each other, sharing a story",
         "single_dominant"),
        
        ("13_art_project", "dual", "both", 
         "Alex and Emma working on an art project together, both holding crayons and drawing on the same paper",
         "both_refs"),
        
        ("14_lunch_sharing", "dual", "both", 
         "Alex and Emma sharing lunch at a table, Alex offering part of his sandwich to Emma, showing generosity",
         "both_refs"),
        
        ("15_playground_fun", "dual", "both", 
         "Alex and Emma playing on playground equipment together, both laughing and having fun, showing their friendship",
         "averaged"),
    ]
    
    try:
        # PHASE 1: Character references with long prompts
        print("\nğŸ‘¦ğŸ‘§ PHASE 1: Character References (For Comparison)")
        print("-" * 60)
        
        print("ğŸ¨ Generating Alex reference...")
        alex_prompt = prompts.get_reference_prompt("Alex")
        negative = prompts.get_negative_prompt()
        
        print(f"   ğŸ“Š Alex prompt length: {len(alex_prompt.split())} words")
        
        alex_ref = pipeline.generate_reference_with_compel(
            alex_prompt, negative,
            num_inference_steps=30,
            guidance_scale=7.5,
            height=1024, width=1024,
            generator=torch.Generator(pipeline.device).manual_seed(1000)
        )
        
        print("ğŸ¨ Generating Emma reference...")
        emma_prompt = prompts.get_reference_prompt("Emma")
        
        print(f"   ğŸ“Š Emma prompt length: {len(emma_prompt.split())} words")
        
        emma_ref = pipeline.generate_reference_with_compel(
            emma_prompt, negative,
            num_inference_steps=30,
            guidance_scale=7.5,
            height=1024, width=1024,
            generator=torch.Generator(pipeline.device).manual_seed(2000)
        )
        
        if not alex_ref or not emma_ref:
            print("âŒ Character reference generation failed")
            return
        
        alex_ref.save(os.path.join(output_dir, "alex_reference.png"))
        emma_ref.save(os.path.join(output_dir, "emma_reference.png"))
        print("âœ… Character references saved")
        
        # PHASE 2: Load IP-Adapter
        print("\nğŸ”„ Loading IP-Adapter (NO masking support)...")
        if not pipeline.load_ip_adapter_simple():
            print("âŒ IP-Adapter loading failed")
            return
        
        # PHASE 3: Generate scenes to demonstrate blending issues
        print(f"\nğŸ¬ PHASE 3: Blending Demo Scenes ({len(blending_demo_scenes)} total)")
        print("-" * 70)
        
        results = []
        total_time = 0
        blending_issues = []
        
        for i, scene_data in enumerate(blending_demo_scenes):
            if len(scene_data) == 5:
                scene_name, scene_type, character_focus, action, blending_method = scene_data
            else:
                scene_name, scene_type, character_focus, action = scene_data
                blending_method = "both_refs"
            
            print(f"\nğŸ¨ Scene {i+1}: {scene_name} ({scene_type})")
            if scene_type == "dual":
                print(f"   âš ï¸ Blending method: {blending_method} - expect issues!")
            
            prompt = prompts.get_scene_prompt("social skills", character_focus, action)
            output_path = os.path.join(output_dir, f"{scene_name}.png")
            
            print(f"   ğŸ“Š Scene prompt length: {len(prompt.split())} words")
            
            start_time = time.time()
            
            # Use appropriate generation method
            if scene_type == "single":
                character_ref = alex_ref if character_focus == "Alex" else emma_ref
                image = pipeline.generate_single_character_scene_with_compel(
                    prompt, negative, character_ref,
                    num_inference_steps=25,
                    guidance_scale=7.5,
                    height=1024, width=1024,
                    generator=torch.Generator(pipeline.device).manual_seed(1000 + i)
                )
            else:  # dual - will show blending issues
                image = pipeline.generate_dual_character_scene_NO_MASKING(
                    prompt, negative, alex_ref, emma_ref,
                    num_inference_steps=25,
                    guidance_scale=7.5,
                    height=1024, width=1024,
                    generator=torch.Generator(pipeline.device).manual_seed(1000 + i),
                    blending_method=blending_method
                )
                blending_issues.append(scene_name)
            
            scene_time = time.time() - start_time
            total_time += scene_time
            
            if image:
                image.save(output_path, quality=95, optimize=True)
                results.append(scene_name)
                print(f"   âœ… Generated: {scene_name} ({scene_time:.1f}s)")
                if scene_type == "dual":
                    print(f"   ğŸ“ Check for blending issues in: {scene_name}")
            else:
                print(f"   âŒ Failed: {scene_name}")
        
        # Results
        print("\n" + "=" * 70)
        print("ğŸš€ NO MASKING DEMO RESULTS - CHARACTER BLENDING SHOWCASE")
        print("=" * 70)
        
        success_rate = len(results) / len(blending_demo_scenes) * 100
        avg_time = total_time / len(blending_demo_scenes) if blending_demo_scenes else 0
        
        print(f"âœ“ Success rate: {success_rate:.1f}% ({len(results)}/{len(blending_demo_scenes)})")
        print(f"âœ“ Average time: {avg_time:.1f}s per scene")
        print(f"âœ“ Total time: {total_time/60:.1f} minutes")
        print(f"âœ“ Used Compel for long prompts")
        print(f"âš ï¸ NO masking used - expect character blending!")
        
        if results:
            print("\nğŸ“‹ Generated scenes:")
            for result in results:
                print(f"   â€¢ {result}")
        
        if blending_issues:
            print("\nâš ï¸ SCENES WITH EXPECTED BLENDING ISSUES:")
            for issue in blending_issues:
                print(f"   â€¢ {issue} - check for character merging/blending")
        
        print("\nğŸ”¬ RESEARCH PAPER ANALYSIS GUIDE:")
        print("   ğŸ“Š WHAT TO LOOK FOR IN DUAL CHARACTER SCENES:")
        print("     â€¢ Character feature mixing (Alex's hair + Emma's face)")
        print("     â€¢ One character completely missing")
        print("     â€¢ Hybrid clothing (blue-pink blended shirts)")
        print("     â€¢ Inconsistent character positioning")
        print("     â€¢ Facial feature averaging/morphing")
        print("     â€¢ Hair color blending (brown-blonde mix)")
        print("     â€¢ Size/proportion inconsistencies")
        print("     â€¢ Clothing pattern conflicts")
        
        print("\n   ğŸ“ˆ COMPARISON METRICS FOR YOUR PAPER:")
        print("     â€¢ Character recognition accuracy")
        print("     â€¢ Feature consistency across scenes")
        print("     â€¢ Spatial separation quality")
        print("     â€¢ Individual character preservation")
        print("     â€¢ Color palette integrity")
        
        print("\n   ğŸ“ DOCUMENTATION SUGGESTIONS:")
        print("     â€¢ Compare single vs dual scene quality scores")
        print("     â€¢ Document specific blending artifacts")
        print("     â€¢ Measure character feature preservation")
        print("     â€¢ Analyze spatial distribution problems")
        print("     â€¢ Quantify the improvement with masking")
        
        print("\nğŸ‰ DEMO ADVANTAGES FOR RESEARCH:")
        print("   â€¢ Clear demonstration of the core problem")
        print("   â€¢ Multiple failure modes documented")
        print("   â€¢ Provides quantitative comparison baseline")
        print("   â€¢ Shows why masking is technically necessary")
        print("   â€¢ Validates your solution's importance")
        print("   â€¢ Creates compelling before/after narrative")
        
        if success_rate >= 70:
            print("\nğŸš€ COMPREHENSIVE BLENDING DEMO SUCCESS!")
            print("   ğŸ“š Complete story sequence with blending issues")
            print("   ğŸ­ Multiple failure modes demonstrated")
            print("   ğŸ¨ Perfect for research paper methodology section")
            print("   âœ¨ Shows the problem your solution addresses!")
            print("   ğŸ“Š Ready for quantitative analysis!")
        
        print(f"\nğŸ“ Outputs: {os.path.abspath(output_dir)}/")
        print("\nğŸ“ FOR YOUR RESEARCH PAPER:")
        print("   ğŸ“‹ METHODOLOGY SECTION:")
        print("     â€¢ Use single character scenes as baseline quality")
        print("     â€¢ Document dual character failure modes")
        print("     â€¢ Show progression of story with/without masking")
        print("   ğŸ“Š RESULTS SECTION:")
        print("     â€¢ Quantify character preservation metrics")
        print("     â€¢ Compare spatial consistency scores")
        print("     â€¢ Measure feature blending artifacts")
        print("   ğŸ“ˆ DISCUSSION SECTION:")
        print("     â€¢ Explain why masking solves these issues")
        print("     â€¢ Demonstrate technical necessity of your approach")
        print("     â€¢ Show improvement in narrative coherence")
        print("   ğŸ–¼ï¸ FIGURES:")
        print("     â€¢ Before/after comparison grids")
        print("     â€¢ Character consistency analysis")
        print("     â€¢ Story progression visualization")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Interrupted")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        traceback.print_exc()
    
    finally:
        # Cleanup
        if pipeline.pipeline:
            del pipeline.pipeline
        if pipeline.compel:
            del pipeline.compel
        torch.cuda.empty_cache()
        print("âœ… Complete")


if __name__ == "__main__":
    main()