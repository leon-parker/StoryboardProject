# fixed_realcartoon_storydiffusion.py
"""
FIXED RealCartoon StoryDiffusion - No More Weird Story Frames
Using the OFFICIAL StoryDiffusion approach + proper step counting
"""

import sys
import os
import torch
import numpy as np
import random
import copy
from PIL import Image, ImageDraw, ImageFont
from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler

# Try to import official StoryDiffusion
try:
    sys.path.insert(0, '.')
    from utils.gradio_utils import SpatialAttnProcessor2_0
    OFFICIAL_STORYDIFFUSION = True
    print("‚úÖ Official StoryDiffusion components found")
except ImportError:
    print("‚ö†Ô∏è Official StoryDiffusion not found - using FIXED custom implementation")
    OFFICIAL_STORYDIFFUSION = False

# FIXED custom processor with proper step counting
class FixedRealCartoonProcessor:
    """
    FIXED StoryDiffusion processor that actually works
    """
    def __init__(self, hidden_size=None, cross_attention_dim=None):
        self.hidden_size = hidden_size
        self.cross_attention_dim = cross_attention_dim
        self.is_self_attention = cross_attention_dim is None
        self.layer_name = None  # Will be set during registration
        
    def __call__(self, attn, hidden_states, encoder_hidden_states=None, attention_mask=None, temb=None):
        global state
        
        # FIX #1: Proper step counting per layer
        step_key = f"{state.current_character}_{self.layer_name}_{state.denoising_step}"
        
        # Reference mode: Store features with proper indexing
        if state.is_reference_mode and state.current_character and self.is_self_attention:
            if step_key not in state.reference_features:
                # Store high-quality features for this specific layer and step
                stored = hidden_states[0:1].clone().detach()
                state.reference_features[step_key] = stored
                # print(f"üìù Stored: {step_key} shape: {stored.shape}")
        
        # Story mode: Apply consistency with proper indexing
        elif not state.is_reference_mode and state.current_character and self.is_self_attention:
            if step_key in state.reference_features:
                try:
                    stored = state.reference_features[step_key].to(hidden_states.device, dtype=hidden_states.dtype)
                    
                    # Only blend if shapes match exactly (no forced reshaping)
                    if stored.shape == hidden_states[0:1].shape:
                        batch_size = hidden_states.shape[0]
                        if batch_size > 1:
                            stored = stored.repeat(batch_size, 1, 1)
                        
                        # Strong consistency for cartoon characters
                        strength = state.consistency_strength
                        hidden_states = hidden_states * (1.0 - strength) + stored * strength
                        # print(f"‚úÖ Blended: {step_key} strength: {strength}")
                    else:
                        pass  # Skip if shapes don't match exactly
                        # print(f"‚ö†Ô∏è Shape mismatch: {step_key} stored: {stored.shape} vs current: {hidden_states[0:1].shape}")
                        
                except Exception as e:
                    pass  # Continue with normal processing
                    # print(f"‚ùå Blend failed: {step_key} - {e}")
        
        return self._standard_attention(attn, hidden_states, encoder_hidden_states, attention_mask, temb)
    
    def _standard_attention(self, attn, hidden_states, encoder_hidden_states=None, attention_mask=None, temb=None):
        """Standard attention processing"""
        residual = hidden_states

        if attn.spatial_norm is not None:
            hidden_states = attn.spatial_norm(hidden_states, temb)

        input_ndim = hidden_states.ndim
        if input_ndim == 4:
            batch_size, channel, height, width = hidden_states.shape
            hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)

        batch_size, sequence_length, channel = hidden_states.shape

        if attn.group_norm is not None:
            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)

        query = attn.to_q(hidden_states)

        if encoder_hidden_states is None:
            encoder_hidden_states = hidden_states

        key = attn.to_k(encoder_hidden_states)
        value = attn.to_v(encoder_hidden_states)

        inner_dim = key.shape[-1]
        head_dim = inner_dim // attn.heads

        query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)
        key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)
        value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)

        hidden_states = torch.nn.functional.scaled_dot_product_attention(
            query, key, value, attn_mask=None, dropout_p=0.0, is_causal=False
        )

        hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, attn.heads * head_dim)
        hidden_states = hidden_states.to(query.dtype)

        hidden_states = attn.to_out[0](hidden_states)
        hidden_states = attn.to_out[1](hidden_states)

        if input_ndim == 4:
            hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)

        if attn.residual_connection:
            hidden_states = hidden_states + residual

        hidden_states = hidden_states / attn.rescale_output_factor

        return hidden_states

# FIXED global state with proper step tracking
class FixedStoryState:
    def __init__(self):
        self.reference_features = {}
        self.current_character = None
        self.is_reference_mode = True
        self.denoising_step = 0
        self.consistency_strength = 0.8  # Strong consistency for cartoons

    def reset_for_new_generation(self):
        """Reset for a new image generation"""
        self.denoising_step = 0

    def increment_step(self):
        """Increment denoising step"""
        self.denoising_step += 1

state = FixedStoryState()

def setup_seed(seed):
    """Setup random seeds"""
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

def setup_realcartoon_pipeline(model_path, device="cuda"):
    """Setup pipeline optimized for RealCartoon XL v7"""
    print("üé® FIXED REALCARTOON XL v7 STORYDIFFUSION")
    print("üîß Proper step counting + ALL self-attention layers")
    print("üéØ No more weird story frames!")
    print("=" * 60)
    
    # Load RealCartoon XL v7
    pipe = StableDiffusionXLPipeline.from_single_file(
        model_path,
        torch_dtype=torch.float16,
        use_safetensors=True
    ).to(device)
    
    # Optimize scheduler for RealCartoon
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(
        pipe.scheduler.config,
        use_karras_sigmas=True,
        algorithm_type="dpmsolver++",
        solver_order=2
    )
    
    # Memory optimizations
    pipe.enable_vae_slicing()
    pipe.enable_model_cpu_offload()
    pipe.enable_attention_slicing(1)
    
    try:
        pipe.enable_xformers_memory_efficient_attention()
        print("‚úÖ xFormers enabled")
    except:
        print("‚ö†Ô∏è xFormers not available")
    
    return pipe

def setup_fixed_storydiffusion(pipe):
    """
    Setup FIXED StoryDiffusion - applies to ALL self-attention layers
    """
    if OFFICIAL_STORYDIFFUSION:
        print("üîå Using OFFICIAL StoryDiffusion (recommended)")
        
        # Sync global variables with official implementation
        import utils.gradio_utils as gradio_utils
        gradio_utils.total_count = 0
        gradio_utils.attn_count = 0
        gradio_utils.cur_step = 0
        gradio_utils.write = True  # Start in reference mode
        gradio_utils.height = 1024
        gradio_utils.width = 1024
        gradio_utils.sa32 = 0.8
        gradio_utils.sa64 = 0.8
        gradio_utils.sa16 = 0.8
        gradio_utils.mask1024 = None
        gradio_utils.mask4096 = None
        
        # Apply official processors
        attn_procs = {}
        processor_count = 0
        
        for name in pipe.unet.attn_processors.keys():
            cross_attention_dim = (
                None if name.endswith("attn1.processor") 
                else pipe.unet.config.cross_attention_dim
            )
            
            if cross_attention_dim is None:  # Self-attention
                attn_procs[name] = SpatialAttnProcessor2_0(
                    hidden_size=pipe.unet.config.block_out_channels[-1],
                    cross_attention_dim=cross_attention_dim
                )
                processor_count += 1
            else:
                attn_procs[name] = pipe.unet.attn_processors[name]
        
        pipe.unet.set_attn_processor(copy.deepcopy(attn_procs))
        print(f"‚úÖ Applied OFFICIAL StoryDiffusion to {processor_count} layers")
        
    else:
        print("üîß Using FIXED custom implementation")
        
        # FIX #2: Apply to ALL self-attention layers (not just up-blocks)
        processor_count = 0
        attn_procs = {}
        
        for name in pipe.unet.attn_processors.keys():
            cross_attention_dim = (
                None if name.endswith("attn1.processor") 
                else pipe.unet.config.cross_attention_dim
            )
            
            # FIXED: Apply to ALL self-attention layers
            if cross_attention_dim is None:
                processor = FixedRealCartoonProcessor(
                    hidden_size=pipe.unet.config.block_out_channels[-1],
                    cross_attention_dim=cross_attention_dim
                )
                processor.layer_name = name  # Store layer name for indexing
                attn_procs[name] = processor
                processor_count += 1
            else:
                attn_procs[name] = pipe.unet.attn_processors[name]
        
        pipe.unet.set_attn_processor(copy.deepcopy(attn_procs))
        print(f"‚úÖ Applied FIXED processors to {processor_count} self-attention layers")
    
    return pipe

def set_storydiffusion_mode(is_reference=True):
    """Set StoryDiffusion mode with proper global sync"""
    global state
    
    if OFFICIAL_STORYDIFFUSION:
        import utils.gradio_utils as gradio_utils
        gradio_utils.write = is_reference
        gradio_utils.cur_step = 0
        gradio_utils.attn_count = 0
    
    state.is_reference_mode = is_reference
    state.reset_for_new_generation()
    
    mode = "REFERENCE" if is_reference else "STORY"
    print(f"üîÑ Mode: {mode}")

# Hook to increment step counter during generation
original_unet_forward = None

def patched_unet_forward(self, *args, **kwargs):
    """Patched UNet forward to increment step counter"""
    global state
    if not OFFICIAL_STORYDIFFUSION:
        state.increment_step()
    result = original_unet_forward(*args, **kwargs)
    return result

def generate_fixed_references(pipe, character_desc, reference_prompts, seed=12345):
    """Generate reference images with FIXED StoryDiffusion"""
    global state, original_unet_forward
    
    print(f"\nüé¨ REFERENCE GENERATION")
    set_storydiffusion_mode(is_reference=True)
    state.current_character = "main_character"
    
    # Patch UNet for step counting (if using custom implementation)
    if not OFFICIAL_STORYDIFFUSION and original_unet_forward is None:
        original_unet_forward = pipe.unet.forward
        pipe.unet.forward = patched_unet_forward.__get__(pipe.unet, pipe.unet.__class__)
    
    reference_images = []
    
    for i, prompt in enumerate(reference_prompts):
        state.reset_for_new_generation()
        
        # Setup seed
        ref_seed = seed + i * 111
        setup_seed(ref_seed)
        generator = torch.Generator(device=pipe.device).manual_seed(ref_seed)
        
        # Enhanced prompt for RealCartoon
        enhanced_prompt = f"masterpiece, best quality, anime portrait of {character_desc}, {prompt}, beautiful anime art style, detailed cartoon illustration, vibrant colors"
        negative_prompt = "photorealistic, realistic, 3d render, blurry, low quality, bad anatomy, bad hands, missing fingers, extra fingers, mutated hands, deformed, ugly, bad proportions, extra limbs, malformed limbs, bad eyes, cross-eyed, different eyes, inconsistent character, multiple people, different person"
        
        print(f"  üé® Reference {i+1}: {prompt[:50]}...")
        
        image = pipe(
            prompt=enhanced_prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=30,
            guidance_scale=8.0,
            height=1024,
            width=1024,
            generator=generator,
        ).images[0]
        
        reference_images.append(image)
        print(f"  ‚úÖ Generated reference {i+1}")
    
    print(f"‚úÖ Generated {len(reference_images)} reference images")
    print(f"üìä Stored {len(state.reference_features)} feature tensors")
    return reference_images

def generate_fixed_story(pipe, character_desc, story_prompts, seed=22345):
    """Generate story images with FIXED consistency"""
    global state
    
    print(f"\nüé¨ STORY GENERATION - FIXED")
    set_storydiffusion_mode(is_reference=False)
    state.current_character = "main_character"
    
    story_images = []
    
    for i, prompt in enumerate(story_prompts):
        state.reset_for_new_generation()
        
        # Closer seeds for consistency
        story_seed = seed + i * 50  # Closer seeds
        setup_seed(story_seed)
        generator = torch.Generator(device=pipe.device).manual_seed(story_seed)
        
        # STRONG character consistency keywords
        specific_char = f"the exact same {character_desc}, identical face, same character, consistent features"
        enhanced_prompt = f"masterpiece, best quality, anime portrait of {specific_char}, {prompt}, beautiful anime art style, detailed cartoon illustration, vibrant colors, character consistency"
        negative_prompt = "photorealistic, realistic, 3d render, blurry, low quality, bad anatomy, bad hands, missing fingers, extra fingers, mutated hands, deformed, ugly, bad proportions, extra limbs, malformed limbs, bad eyes, cross-eyed, different eyes, inconsistent character, multiple people, different person, changing face, inconsistent art style"
        
        print(f"  üé® Story {i+1}: {prompt[:50]}...")
        
        image = pipe(
            prompt=enhanced_prompt,
            negative_prompt=negative_prompt,
            num_inference_steps=25,
            guidance_scale=7.5,
            height=1024,
            width=1024,
            generator=generator,
        ).images[0]
        
        story_images.append(image)
        print(f"  ‚úÖ Generated story {i+1}")
    
    print(f"‚úÖ Generated {len(story_images)} story images")
    return story_images

def create_comparison_grid(reference_images, story_images):
    """Create comparison grid"""
    all_images = reference_images + story_images
    ref_count = len(reference_images)
    
    # 2-row layout: references on top, story on bottom
    cols = max(ref_count, len(story_images))
    img_size = 512
    margin = 10
    
    grid_width = cols * img_size + (cols - 1) * margin
    grid_height = 2 * img_size + margin
    
    grid = Image.new('RGB', (grid_width, grid_height), 'white')
    
    # Top row: references
    for i, img in enumerate(reference_images):
        x = i * (img_size + margin)
        resized = img.resize((img_size, img_size), Image.Resampling.LANCZOS)
        grid.paste(resized, (x, 0))
    
    # Bottom row: story
    for i, img in enumerate(story_images):
        x = i * (img_size + margin)
        resized = img.resize((img_size, img_size), Image.Resampling.LANCZOS)
        grid.paste(resized, (x, img_size + margin))
    
    return grid

def main():
    """Test the FIXED StoryDiffusion"""
    
    # Find model
    possible_paths = [
        "../models/realcartoonxl_v7.safetensors",
        "../../models/realcartoonxl_v7.safetensors",
        "../realcartoonxl_v7.safetensors",
        "models/realcartoonxl_v7.safetensors"
    ]
    
    model_path = None
    for path in possible_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if not model_path:
        print("‚ùå RealCartoon XL v7 model not found!")
        return
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:
        # Setup pipeline
        pipe = setup_realcartoon_pipeline(model_path, device)
        
        # Setup FIXED StoryDiffusion
        pipe = setup_fixed_storydiffusion(pipe)
        
        # Define character and prompts
        character_desc = "a beautiful anime girl with long flowing brown hair, bright blue eyes, soft facial features, cute expression"
        
        reference_prompts = [
            "facing forward, neutral expression, soft lighting",
            "gentle smile, looking directly at viewer",
            "happy cheerful expression, detailed artwork"
        ]
        
        story_prompts = [
            "wearing school uniform, student outfit",
            "wearing casual summer dress, relaxed expression", 
            "wearing winter coat and scarf, cozy aesthetic",
            "wearing elegant formal dress, sophisticated portrait",
            "wearing sporty athletic wear, energetic expression"
        ]
        
        # Generate with FIXED implementation
        reference_images = generate_fixed_references(
            pipe, character_desc, reference_prompts, seed=12345
        )
        
        story_images = generate_fixed_story(
            pipe, character_desc, story_prompts, seed=22345
        )
        
        # Save results
        output_dir = "fixed_realcartoon_output"
        os.makedirs(output_dir, exist_ok=True)
        
        # Save individual images
        for i, img in enumerate(reference_images):
            img.save(f"{output_dir}/fixed_ref_{i+1:02d}.png")
        
        for i, img in enumerate(story_images):
            img.save(f"{output_dir}/fixed_story_{i+1:02d}.png")
        
        # Create comparison grid
        grid = create_comparison_grid(reference_images, story_images)
        grid.save(f"{output_dir}/fixed_comparison.png")
        
        print(f"\nüéâ FIXED STORYDIFFUSION COMPLETE!")
        print(f"‚úÖ Generated {len(reference_images)} references + {len(story_images)} story images")
        print(f"üìÅ Saved to: {output_dir}/")
        print(f"\nüîß FIXES APPLIED:")
        print(f"  ‚úÖ Proper step counting per layer")
        print(f"  ‚úÖ ALL self-attention layers (not just up-blocks)")
        print(f"  ‚úÖ Exact shape matching (no forced reshaping)")
        print(f"  ‚úÖ Strong consistency (80%) for cartoon characters")
        print(f"  ‚úÖ {'Official' if OFFICIAL_STORYDIFFUSION else 'Fixed custom'} implementation")
        print(f"\nüí° Story frames should now look PERFECT!")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()