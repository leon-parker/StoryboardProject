"""
REALCARTOON XL V7 WITH COMPEL LONG PROMPTS - NO MASKING VERSION
Demonstrates character blending issues without masking for research paper!

‚úÖ KEY FEATURES:
- Uses Compel library to handle prompts longer than 77 tokens
- NO masking or ControlNet - shows raw character blending issues
- Detailed prompts for better SDXL results
- Simple IP-Adapter integration without spatial control
- Perfect for demonstrating WHY masking is necessary!
"""

import os
import torch
import time
from PIL import Image
from diffusers import StableDiffusionXLPipeline, DDIMScheduler
from transformers import CLIPVisionModelWithProjection
from compel import Compel, ReturnedEmbeddingsType
import traceback
import gc

class CompelNoMaskingPipeline:
    """Pipeline with Compel support for long prompts - NO MASKING to show character blending"""
    
    def __init__(self, model_path, device="cuda"):
        self.model_path = model_path
        self.device = device
        self.pipeline = None
        self.compel = None
        self.ip_adapter_loaded = False
        
    def setup_pipeline_with_compel(self):
        """Setup pipeline with Compel for long prompt support - NO ControlNet or masking"""
        print("üîß Setting up RealCartoon XL v7 with Compel (NO MASKING - Character Blending Demo)...")
        
        try:
            # Verify model
            size_gb = os.path.getsize(self.model_path) / (1024**3)
            print(f"   üìä Model: {size_gb:.1f}GB")
            if 6.5 <= size_gb <= 7.5:
                print("   ‚úÖ RealCartoon XL v7 confirmed")
            
            # Load image encoder first
            print("   üì∏ Loading image encoder...")
            image_encoder = CLIPVisionModelWithProjection.from_pretrained(
                "h94/IP-Adapter",
                subfolder="models/image_encoder",
                torch_dtype=torch.float16,
            )
            
            # Load ONLY regular pipeline - no ControlNet
            print("   üéØ Loading RealCartoon XL v7 (regular pipeline only)...")
            self.pipeline = StableDiffusionXLPipeline.from_single_file(
                self.model_path,
                torch_dtype=torch.float16,
                use_safetensors=True,
                image_encoder=image_encoder,
                safety_checker=None,
                requires_safety_checker=False
            ).to(self.device)
            
            # Setup scheduler
            print("   üìê Setting up scheduler...")
            self.pipeline.scheduler = DDIMScheduler.from_config(self.pipeline.scheduler.config)
            self.pipeline.enable_vae_tiling()
            
            # Setup Compel for long prompts (CRITICAL!)
            print("   üöÄ Setting up Compel for long prompts...")
            self.compel = Compel(
                tokenizer=[self.pipeline.tokenizer, self.pipeline.tokenizer_2],
                text_encoder=[self.pipeline.text_encoder, self.pipeline.text_encoder_2],
                returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,
                requires_pooled=[False, True],
                truncate_long_prompts=False  # This enables long prompts!
            )
            
            print("‚úÖ Pipeline with Compel ready!")
            print("   üéØ Long prompts (>77 tokens) now supported!")
            print("   ‚ö†Ô∏è NO MASKING - will demonstrate character blending issues!")
            return True
            
        except Exception as e:
            print(f"‚ùå Pipeline setup failed: {e}")
            traceback.print_exc()
            return False
    
    def load_ip_adapter_simple(self):
        """Load IP-Adapter with simple configuration"""
        print("\nüñºÔ∏è Loading IP-Adapter (NO masking support)...")
        
        try:
            # Load IP-Adapter for regular pipeline
            self.pipeline.load_ip_adapter(
                "h94/IP-Adapter",
                subfolder="sdxl_models",
                weight_name=["ip-adapter-plus-face_sdxl_vit-h.safetensors"]
            )
            self.ip_adapter_loaded = True
            print("   ‚úÖ IP-Adapter loaded!")
            print("   ‚ö†Ô∏è NO masking capability - characters will blend!")
            
            return True
            
        except Exception as e:
            print(f"   ‚ùå IP-Adapter failed: {e}")
            return False
    
    def encode_prompts_with_compel(self, positive_prompt, negative_prompt):
        """Encode both prompts using Compel and ensure matching shapes"""
        try:
            print(f"   üìù Encoding positive prompt: {positive_prompt[:100]}{'...' if len(positive_prompt) > 100 else ''}")
            print(f"   üìä Positive prompt length: {len(positive_prompt.split())} words")
            
            print(f"   üìù Encoding negative prompt: {negative_prompt[:100]}{'...' if len(negative_prompt) > 100 else ''}")
            print(f"   üìä Negative prompt length: {len(negative_prompt.split())} words")
            
            # Use Compel to handle both prompts
            positive_conditioning, positive_pooled = self.compel(positive_prompt)
            negative_conditioning, negative_pooled = self.compel(negative_prompt)
            
            # CRITICAL: Pad conditioning tensors to same length to avoid shape mismatch
            print("   üîß Padding tensors to same length...")
            [positive_conditioning, negative_conditioning] = self.compel.pad_conditioning_tensors_to_same_length(
                [positive_conditioning, negative_conditioning]
            )
            
            print(f"   ‚úÖ Final tensor shapes: pos={positive_conditioning.shape}, neg={negative_conditioning.shape}")
            
            return positive_conditioning, positive_pooled, negative_conditioning, negative_pooled
            
        except Exception as e:
            print(f"   ‚ùå Compel encoding failed: {e}")
            traceback.print_exc()
            return None, None, None, None
    
    def generate_reference_with_compel(self, prompt, negative_prompt, **kwargs):
        """Generate character reference using Compel for long prompts"""
        try:
            # Encode both prompts with Compel and ensure matching shapes
            prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled = self.encode_prompts_with_compel(
                prompt, negative_prompt
            )
            
            if prompt_embeds is None:
                return None
            
            result = self.pipeline(
                prompt_embeds=prompt_embeds,
                pooled_prompt_embeds=pooled_prompt_embeds,
                negative_prompt_embeds=negative_embeds,
                negative_pooled_prompt_embeds=negative_pooled,
                **kwargs
            )
            
            # Clean up embeddings to save memory
            del prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled
            gc.collect()
            
            return result.images[0] if result and result.images else None
            
        except Exception as e:
            print(f"‚ùå Reference generation failed: {e}")
            traceback.print_exc()
            return None
    
    def generate_single_character_scene_with_compel(self, prompt, negative_prompt, character_ref, **kwargs):
        """Generate single character scene using Compel"""
        
        if not self.ip_adapter_loaded:
            print("   ‚ùå IP-Adapter not loaded!")
            return None
        
        try:
            # Encode both prompts with Compel and ensure matching shapes
            prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled = self.encode_prompts_with_compel(
                prompt, negative_prompt
            )
            
            if prompt_embeds is None:
                return None
            
            # Simple IP-Adapter configuration
            self.pipeline.set_ip_adapter_scale(0.7)
            
            result = self.pipeline(
                prompt_embeds=prompt_embeds,
                pooled_prompt_embeds=pooled_prompt_embeds,
                negative_prompt_embeds=negative_embeds,
                negative_pooled_prompt_embeds=negative_pooled,
                ip_adapter_image=character_ref,
                **kwargs
            )
            
            # Clean up embeddings
            del prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled
            gc.collect()
            
            return result.images[0] if result and result.images else None
            
        except Exception as e:
            print(f"‚ùå Single character generation failed: {e}")
            traceback.print_exc()
            return None
    
    def generate_dual_character_scene_NO_MASKING(self, prompt, negative_prompt, alex_ref, emma_ref, **kwargs):
        """Generate dual character scene WITHOUT masking - demonstrates blending issues!"""
        
        if not self.ip_adapter_loaded:
            print("   ‚ùå IP-Adapter not loaded!")
            return None
        
        try:
            print("   ‚ö†Ô∏è Generating dual characters WITHOUT masking - expect blending issues!")
            
            # Encode prompts with Compel
            prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled = self.encode_prompts_with_compel(
                prompt, negative_prompt
            )
            
            if prompt_embeds is None:
                return None
            
            # NO MASKING - just pass both character references directly
            # This will cause characters to blend/merge together!
            self.pipeline.set_ip_adapter_scale(0.7)
            
            # Try different approaches to show various blending issues:
            blending_method = kwargs.pop('blending_method', 'both_refs')
            
            if blending_method == 'both_refs':
                # Method 1: Pass both references - they will compete and blend
                print("   üìù Method: Both references (will compete and blend)")
                ip_adapter_image = [alex_ref, emma_ref]
                
            elif blending_method == 'single_dominant':
                # Method 2: Use one reference - other character gets lost
                print("   üìù Method: Single reference (one character dominates)")
                ip_adapter_image = alex_ref  # Emma will likely be lost or distorted
                
            elif blending_method == 'averaged':
                # Method 3: Try to blend references - creates hybrid features
                print("   üìù Method: Reference blending (creates hybrid features)")
                ip_adapter_image = [alex_ref, emma_ref]
                self.pipeline.set_ip_adapter_scale([0.5, 0.5])  # Equal weights
            
            # Generate WITHOUT any spatial control or masking
            result = self.pipeline(
                prompt_embeds=prompt_embeds,
                pooled_prompt_embeds=pooled_prompt_embeds,
                negative_prompt_embeds=negative_embeds,
                negative_pooled_prompt_embeds=negative_pooled,
                ip_adapter_image=ip_adapter_image,
                **kwargs
            )
            
            print("   ‚ö†Ô∏è Generated without masking - check for character blending!")
            
            # Clean up embeddings
            del prompt_embeds, pooled_prompt_embeds, negative_embeds, negative_pooled
            gc.collect()
            
            return result.images[0] if result and result.images else None
            
        except Exception as e:
            print(f"‚ùå Dual character generation failed: {e}")
            traceback.print_exc()
            return None

class DetailedEducationalPrompts:
    """Detailed prompts optimized for SDXL with Compel (no 77-token limit!)"""
    
    def __init__(self):
        # Detailed character descriptions for SDXL
        self.alex_base = """Alex, a cheerful 6-year-old boy with short neat black hair and warm expressive brown eyes, 
        wearing a comfortable bright blue t-shirt and dark comfortable pants, displaying a genuine friendly smile 
        and kind facial expression, with a natural child-like innocent demeanor"""
        
        self.emma_base = """Emma, a sweet 6-year-old girl with blonde hair styled in neat ponytails held by blue ribbons, 
        bright blue eyes full of curiosity, wearing a soft pink cardigan over a white shirt, 
        with a gentle sweet expression and delicate youthful features, displaying a thoughtful and sensitive nature"""
        
        self.setting_base = """bright cheerful classroom environment with warm natural lighting, 
        educational cartoon art style with soft colors and clean lines, child-friendly atmosphere, 
        professional educational illustration quality"""
        
    def get_reference_prompt(self, character_name):
        """Detailed reference prompts (no token limit with Compel!)"""
        if character_name == "Alex":
            return f"""{self.alex_base}, character reference sheet, full body portrait, 
            standing pose, clean white background, high quality digital illustration, 
            consistent character design, educational animation style, bright even lighting, 
            clear details, professional character concept art"""
        else:
            return f"""{self.emma_base}, character reference sheet, full body portrait, 
            standing pose, clean white background, high quality digital illustration, 
            consistent character design, educational animation style, bright even lighting, 
            clear details, professional character concept art"""
    
    def get_scene_prompt(self, skill, character_focus, action):
        """Detailed scene prompts - asks for TWO characters but without masking they will blend!"""
        if character_focus == "Alex":
            return f"""{self.alex_base}, {action}, {self.setting_base}, 
            autism education themed illustration, social skills learning context, 
            high quality educational content, detailed facial expressions showing emotion, 
            natural body language and gestures, warm inviting atmosphere, 
            child-appropriate content, positive educational messaging"""
        elif character_focus == "Emma":
            return f"""{self.emma_base}, {action}, {self.setting_base}, 
            autism education themed illustration, social skills learning context, 
            high quality educational content, detailed facial expressions showing emotion, 
            natural body language and gestures, warm inviting atmosphere, 
            child-appropriate content, positive educational messaging"""
        else:  # both characters - asking for TWO but they will blend without masking!
            return f"""Alex and Emma, two distinct children, Alex with black hair and blue shirt, Emma with blonde ponytails and pink cardigan, {action}, {self.setting_base}, 
            social skills education illustration, autism awareness content, showing positive social interaction, 
            detailed character expressions and body language, warm educational atmosphere, 
            high quality digital illustration, child-friendly educational content, 
            demonstrating friendship and social learning, bright cheerful colors, 
            two separate children, distinct character features, Alex and Emma together"""
    
    def get_negative_prompt(self):
        """Enhanced negative prompt to try to prevent blending (though it won't work without masking)"""
        return """realistic photography, photorealistic, adult faces, teenage appearance, 
        blurry image, low quality, poor resolution, dark lighting, scary atmosphere, 
        inappropriate content, weapons, violence, sad or distressing themes, 
        poor anatomy, distorted faces, multiple heads, extra limbs, 
        bad hands, mutation, deformed features, background characters, other people,
        merged faces, blended features, hybrid characters, face morphing, character fusion"""

def find_realcartoon_model():
    """Find RealCartoon XL v7 model"""
    paths = [
        "../models/realcartoonxl_v7.safetensors",
        "models/realcartoonxl_v7.safetensors",
        "../models/RealCartoon-XL-v7.safetensors"
    ]
    
    for path in paths:
        if os.path.exists(path):
            return path
    return None

def main():
    """RealCartoon XL v7 with Compel Long Prompts - NO MASKING (Character Blending Demo)"""
    print("\n" + "="*70)
    print("üöÄ REALCARTOON XL V7 - NO MASKING VERSION (CHARACTER BLENDING DEMO)")
    print("   Demonstrates WHY masking is necessary for dual character scenes!")
    print("="*70)
    
    print("\nüéØ Demo Features:")
    print("  ‚Ä¢ Uses Compel for long prompts (>77 tokens)")
    print("  ‚Ä¢ NO masking or spatial control")
    print("  ‚Ä¢ NO ControlNet")
    print("  ‚Ä¢ Shows character blending/merging issues")
    print("  ‚Ä¢ Perfect for research paper comparison!")
    print("  ‚Ä¢ Demonstrates the PROBLEM that masking solves")
    
    print("\n‚ö†Ô∏è EXPECTED BLENDING ISSUES:")
    print("  ‚Ä¢ Two characters will merge into one hybrid")
    print("  ‚Ä¢ Alex's features + Emma's features = mixed child")
    print("  ‚Ä¢ Black hair + blonde hair = brown/mixed hair")
    print("  ‚Ä¢ Blue shirt + pink cardigan = purple/mixed clothing")
    print("  ‚Ä¢ Boy + girl features = androgynous appearance")
    print("  ‚Ä¢ One character may dominate the other")
    print("  ‚Ä¢ Character consistency will be lost")
    print("  ‚Ä¢ Impossible to maintain separate identities")
    
    # Check if Compel is installed
    try:
        import compel
        print("  ‚úÖ Compel library detected")
    except ImportError:
        print("  ‚ùå Compel library not found!")
        print("     Install with: pip install compel")
        return
    
    # Find model
    model_path = find_realcartoon_model()
    if not model_path:
        model_path = input("üìÅ Enter RealCartoon XL v7 path: ").strip()
        if not os.path.exists(model_path):
            print("‚ùå Model not found")
            return
    
    output_dir = "character_blending_demo"
    os.makedirs(output_dir, exist_ok=True)
    
    # Setup pipeline with Compel (NO masking/ControlNet)
    pipeline = CompelNoMaskingPipeline(model_path)
    if not pipeline.setup_pipeline_with_compel():
        print("‚ùå Pipeline setup failed")
        return
    
    prompts = DetailedEducationalPrompts()
    
    # Define scenes to showcase character blending/merging issues
    blending_demo_scenes = [
        # Single character scenes for reference
        ("01_alex_reference", "single", "Alex", 
         "Alex alone, looking around the classroom with a concerned and empathetic expression"),
        
        ("02_emma_reference", "single", "Emma", 
         "Emma alone, sitting at a desk with a book, looking sad and hoping for friendship"),
        
        ("03_alex_thinking", "single", "Alex", 
         "Alex alone at his desk with a thinking expression, pondering and contemplating"),
        
        # BLENDING SCENES - will show character merging issues
        ("04_approach_blend", "dual", "both", 
         "Alex walking towards Emma at her desk while Emma looks up hopefully",
         "both_refs"),
        
        ("05_greeting_merge", "dual", "both", 
         "Alex and Emma doing a high five together, both smiling happily",
         "equal_blend"),
        
        ("06_playing_hybrid", "dual", "both", 
         "Alex and Emma playing with educational toys together, showing cooperation",
         "both_refs"),
        
        ("07_sharing_dominant", "dual", "both", 
         "Alex and Emma sharing books and materials, demonstrating friendship",
         "single_dominant"),
        
        ("08_conversation_chaos", "dual", "both", 
         "Alex and Emma having a friendly conversation, sitting at a table",
         "max_chaos"),
        
        ("09_learning_blend", "dual", "both", 
         "Alex and Emma working on a puzzle together, collaborating",
         "equal_blend"),
        
        ("10_comfort_merge", "dual", "both", 
         "Alex gently comforting Emma, showing empathy and kindness",
         "both_refs"),
        
        ("11_celebration_hybrid", "dual", "both", 
         "Alex and Emma jumping with joy, arms raised in celebration",
         "equal_blend"),
        
        ("12_reading_dominant", "dual", "both", 
         "Alex and Emma sitting side by side reading the same book",
         "single_dominant"),
        
        ("13_art_chaos", "dual", "both", 
         "Alex and Emma working on an art project together",
         "max_chaos"),
        
        ("14_lunch_blend", "dual", "both", 
         "Alex and Emma sharing lunch at a table, Alex offering his sandwich",
         "both_refs"),
        
        ("15_playground_merge", "dual", "both", 
         "Alex and Emma playing on playground equipment together, laughing",
         "equal_blend"),
        
        ("16_writing_dominant", "dual", "both", 
         "Alex and Emma writing in notebooks, focused on homework",
         "single_dominant"),
        
        ("17_listening_chaos", "dual", "both", 
         "Alex and Emma listening to teacher, paying attention in class",
         "max_chaos"),
        
        ("18_cleanup_blend", "dual", "both", 
         "Alex and Emma organizing classroom, putting away supplies",
         "both_refs"),
        
        ("19_music_hybrid", "dual", "both", 
         "Alex and Emma playing musical instruments, enjoying music time",
         "equal_blend"),
        
        ("20_helping_merge", "dual", "both", 
         "Alex and Emma helping each other with schoolwork",
         "both_refs"),
        
        ("21_science_dominant", "dual", "both", 
         "Alex and Emma doing science experiment, exploring together",
         "single_dominant"),
        
        ("22_exercise_chaos", "dual", "both", 
         "Alex and Emma doing physical exercise, stretching and moving",
         "max_chaos"),
        
        ("23_library_blend", "dual", "both", 
         "Alex and Emma in library, selecting books and reading quietly",
         "equal_blend"),
        
        ("24_computer_hybrid", "dual", "both", 
         "Alex and Emma using computer, learning technology together",
         "both_refs"),
        
        ("25_goodbye_merge", "dual", "both", 
         "Alex and Emma waving goodbye, end of school day",
         "equal_blend"),
    ]
    
    try:
        # PHASE 1: Character references with long prompts
        print("\nüë¶üëß PHASE 1: Character References (For Comparison)")
        print("-" * 60)
        
        print("üé® Generating Alex reference...")
        alex_prompt = prompts.get_reference_prompt("Alex")
        negative = prompts.get_negative_prompt()
        
        print(f"   üìä Alex prompt length: {len(alex_prompt.split())} words")
        
        alex_ref = pipeline.generate_reference_with_compel(
            alex_prompt, negative,
            num_inference_steps=30,
            guidance_scale=7.5,
            height=1024, width=1024,
            generator=torch.Generator(pipeline.device).manual_seed(1000)
        )
        
        print("üé® Generating Emma reference...")
        emma_prompt = prompts.get_reference_prompt("Emma")
        
        print(f"   üìä Emma prompt length: {len(emma_prompt.split())} words")
        
        emma_ref = pipeline.generate_reference_with_compel(
            emma_prompt, negative,
            num_inference_steps=30,
            guidance_scale=7.5,
            height=1024, width=1024,
            generator=torch.Generator(pipeline.device).manual_seed(2000)
        )
        
        if not alex_ref or not emma_ref:
            print("‚ùå Character reference generation failed")
            return
        
        alex_ref.save(os.path.join(output_dir, "alex_reference.png"))
        emma_ref.save(os.path.join(output_dir, "emma_reference.png"))
        print("‚úÖ Character references saved")
        
        # PHASE 2: Load IP-Adapter
        print("\nüîÑ Loading IP-Adapter (NO masking support)...")
        if not pipeline.load_ip_adapter_simple():
            print("‚ùå IP-Adapter loading failed")
            return
        
        # PHASE 3: Generate scenes to demonstrate blending issues
        print(f"\nüé¨ PHASE 3: Blending Demo Scenes ({len(blending_demo_scenes)} total)")
        print("-" * 70)
        
        results = []
        total_time = 0
        blending_issues = []
        
        for i, scene_data in enumerate(blending_demo_scenes):
            if len(scene_data) == 5:
                scene_name, scene_type, character_focus, action, blending_method = scene_data
            else:
                scene_name, scene_type, character_focus, action = scene_data
                blending_method = "both_refs"
            
            print(f"\nüé® Scene {i+1}: {scene_name} ({scene_type})")
            if scene_type == "dual":
                print(f"   ‚ö†Ô∏è Blending method: {blending_method} - expect issues!")
            
            prompt = prompts.get_scene_prompt("social skills", character_focus, action)
            output_path = os.path.join(output_dir, f"{scene_name}.png")
            
            print(f"   üìä Scene prompt length: {len(prompt.split())} words")
            
            start_time = time.time()
            
            # Use appropriate generation method
            if scene_type == "single":
                character_ref = alex_ref if character_focus == "Alex" else emma_ref
                image = pipeline.generate_single_character_scene_with_compel(
                    prompt, negative, character_ref,
                    num_inference_steps=25,
                    guidance_scale=7.5,
                    height=1024, width=1024,
                    generator=torch.Generator(pipeline.device).manual_seed(1000 + i)
                )
            else:  # dual - will show blending issues
                image = pipeline.generate_dual_character_scene_NO_MASKING(
                    prompt, negative, alex_ref, emma_ref,
                    num_inference_steps=25,
                    guidance_scale=7.5,
                    height=1024, width=1024,
                    generator=torch.Generator(pipeline.device).manual_seed(1000 + i),
                    blending_method=blending_method
                )
                blending_issues.append(scene_name)
            
            scene_time = time.time() - start_time
            total_time += scene_time
            
            if image:
                image.save(output_path, quality=95, optimize=True)
                results.append(scene_name)
                print(f"   ‚úÖ Generated: {scene_name} ({scene_time:.1f}s)")
                if scene_type == "dual":
                    print(f"   üìù Check for blending issues in: {scene_name}")
            else:
                print(f"   ‚ùå Failed: {scene_name}")
        
        # Results
        print("\n" + "=" * 70)
        print("üöÄ NO MASKING DEMO RESULTS - CHARACTER BLENDING SHOWCASE")
        print("=" * 70)
        
        success_rate = len(results) / len(blending_demo_scenes) * 100
        avg_time = total_time / len(blending_demo_scenes) if blending_demo_scenes else 0
        
        print(f"‚úì Success rate: {success_rate:.1f}% ({len(results)}/{len(blending_demo_scenes)})")
        print(f"‚úì Average time: {avg_time:.1f}s per scene")
        print(f"‚úì Total time: {total_time/60:.1f} minutes")
        print(f"‚úì Used Compel for long prompts")
        print(f"‚ö†Ô∏è NO masking used - expect character blending!")
        
        if results:
            print("\nüìã Generated scenes:")
            for result in results:
                print(f"   ‚Ä¢ {result}")
        
        if blending_issues:
            print("\n‚ö†Ô∏è SCENES WITH EXPECTED BLENDING ISSUES:")
            for issue in blending_issues:
                print(f"   ‚Ä¢ {issue} - check for character merging/blending")
        
        print("\nüî¨ RESEARCH PAPER ANALYSIS GUIDE:")
        print("   üìä WHAT TO LOOK FOR IN DUAL CHARACTER SCENES:")
        print("     ‚Ä¢ COMPLETE CHARACTER FUSION - Two become one")
        print("     ‚Ä¢ Impossible hybrid features (Alex's hair + Emma's face)")
        print("     ‚Ä¢ Color blending (blue + pink = purple clothing)")
        print("     ‚Ä¢ Gender confusion (boy + girl = androgynous hybrid)")
        print("     ‚Ä¢ Hair color mixing (black + blonde = brown/mixed)")
        print("     ‚Ä¢ Eye color confusion (brown + blue = impossible color)")
        print("     ‚Ä¢ Clothing pattern fusion (t-shirt + cardigan = hybrid outfit)")
        print("     ‚Ä¢ Complete character disappearance (only one visible)")
        print("     ‚Ä¢ Anatomical impossibilities from feature mixing")
        
        print("\n   üìà EXTREME BLENDING EVIDENCE FOR YOUR PAPER:")
        print("     ‚Ä¢ Character identity loss (neither Alex nor Emma)")
        print("     ‚Ä¢ Impossible physical combinations")
        print("     ‚Ä¢ Complete failure of spatial separation")
        print("     ‚Ä¢ Loss of character consistency")
        print("     ‚Ä¢ Narrative coherence breakdown")
        
        print("\n   üìù DOCUMENTATION FOR DISSERTATION:")
        print("     ‚Ä¢ Screenshot hybrid characters showing feature mixing")
        print("     ‚Ä¢ Compare to clean single character references")
        print("     ‚Ä¢ Document complete loss of character individuality")
        print("     ‚Ä¢ Show progression from two characters to one hybrid")
        print("     ‚Ä¢ Demonstrate why masking is technically essential")
        
        print("\nüéâ DEMO ADVANTAGES FOR RESEARCH:")
        print("   ‚Ä¢ Clear demonstration of the core problem")
        print("   ‚Ä¢ Multiple failure modes documented")
        print("   ‚Ä¢ Provides quantitative comparison baseline")
        print("   ‚Ä¢ Shows why masking is technically necessary")
        print("   ‚Ä¢ Validates your solution's importance")
        print("   ‚Ä¢ Creates compelling before/after narrative")
        
        if success_rate >= 70:
            print("\nüöÄ EXTREME CHARACTER FUSION DEMO SUCCESS!")
            print("   üìö Complete demonstration of character merging")
            print("   üé≠ Two characters becoming one hybrid child")
            print("   üé® Perfect for dissertation visual evidence")
            print("   ‚ú® Shows CRITICAL PROBLEM your masking solves!")
            print("   üìä Ready for academic publication!")
        
        print(f"\nüìÅ Outputs: {os.path.abspath(output_dir)}/")
        print("\nüìù FOR YOUR DISSERTATION:")
        print("   üìã PROBLEM STATEMENT:")
        print("     ‚Ä¢ Use hybrid character images as evidence")
        print("     ‚Ä¢ Show impossible feature combinations")
        print("     ‚Ä¢ Demonstrate complete loss of character identity")
        print("   üìä METHODOLOGY SECTION:")
        print("     ‚Ä¢ Document the technical limitations")
        print("     ‚Ä¢ Show why spatial control is essential")
        print("     ‚Ä¢ Compare single vs merged character results")
        print("   üìà RESULTS & DISCUSSION:")
        print("     ‚Ä¢ Quantify character identity preservation")
        print("     ‚Ä¢ Demonstrate your masking solution's necessity")
        print("     ‚Ä¢ Show improvement in character consistency")
        print("   üñºÔ∏è VISUAL EVIDENCE:")
        print("     ‚Ä¢ Before/after comparison (hybrid vs separated)")
        print("     ‚Ä¢ Character fusion progression examples")
        print("     ‚Ä¢ Feature mixing demonstration grid")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Interrupted")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        traceback.print_exc()
    
    finally:
        # Cleanup
        if pipeline.pipeline:
            del pipeline.pipeline
        if pipeline.compel:
            del pipeline.compel
        torch.cuda.empty_cache()
        print("‚úÖ Complete")


if __name__ == "__main__":
    main()